---
title: "Flu Shot Learning"
author: "Lisa Wilson"
date: "10/6/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

setwd("~/Documents/DrivenData/Flu Shot Learning/")

library(tidymodels)
library(tidyverse)
library(workflows)
library(tune)
library(ranger)
library(naniar)
#library(GGally)
library(nnet)
library(factoextra)
library(xgboost)
```

### Data exploration and manipulation
```{r data}
train_exp <- read.csv("flu_train_features.csv")
train_resp <- read.csv("flu_train_labels.csv")
test_exp <- read.csv("flu_test_features.csv")

summary(train_exp)

# scratch
#classes <- sapply(train_exp, class) 
#str(classes)
#classes == "character"

# could also do recipe step step_string2factor(all_nominal())
train_exp <- train_exp %>% mutate_if(is.character, as.factor)
test_exp <- test_exp %>% mutate_if(is.character, as.factor)
summary(train_exp)
str(train_exp)

train_full <- inner_join(train_resp, train_exp, by = "respondent_id")
train_full <- train_full %>% 
    mutate(h1n1_vaccine = as.factor(h1n1_vaccine), seasonal_vaccine = as.factor(seasonal_vaccine))
head(train_full)

# ggpairs(select_if(train_exp, is.numeric))
# pairs(train_exp[,-1])

summary(train_full$h1n1_vaccine)
summary(train_full$seasonal_vaccine)

# correlation of 0.377 between the two vaccine statuses
# higher than/about equal to correlation b/w vaccine status and whether doctor recommended (below), which has been identified as important varb in random forest and boosted tree models
cor(as.numeric(train_full$h1n1_vaccine), as.numeric(train_full$seasonal_vaccine))

# 0.3938905
cor(as.numeric(train_full$h1n1_vaccine), train_full$doctor_recc_h1n1, use = "complete.obs")
# 0.3691901
cor(as.numeric(train_full$seasonal_vaccine), train_full$doctor_recc_seasonal, use = "complete.obs")
```

```{r data exploration}
# health insurance and H1N1 vaccine
summary(train_full$health_insurance)
head(train_full$health_insurance)
ggplot(data = train_full, aes(x = as.factor(health_insurance))) +
    geom_bar(aes(fill = as.factor(h1n1_vaccine))) +
    scale_fill_brewer(palette = "Set2") + 
    labs(x = "Has health insurance", y = "", fill = "Received H1N1 vaccine")
chisq.test(as.factor(train_full$health_insurance), as.factor(train_full$h1n1_vaccine))
# cor(train_full$health_insurance, train_full$h1n1_vaccine)

# employment_occupation, employment_industry and H1N1 vaccine
ggplot(data = train_full, aes(x = as.factor(h1n1_vaccine))) +
    geom_bar(aes(fill = as.factor(employment_occupation))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Received H1N1 vaccine", y = "", fill = "Employment occupation")
chisq.test(train_full$employment_occupation, train_full$h1n1_vaccine)

ggplot(data = train_full, aes(x = as.factor(h1n1_vaccine))) +
    geom_bar(aes(fill = as.factor(employment_industry))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Received H1N1 vaccine", y = "", fill = "Employment industry")
chisq.test(train_full$employment_industry, train_full$h1n1_vaccine)
```

```{r class imbalance}
# class imbalance in H1N1 vaccine status --> most are 0s, few are 1s
# options: oversampling minority, undersampling majority, class weights
prop.table(table(train_full$h1n1_vaccine))

# more balanced in seasonal vaccine status --> 53% 0s
prop.table(table(train_full$seasonal_vaccine))
```

```{r missing data}
# change blanks to NA
train_full <- mutate_all(train_full, list(~na_if(.,""))) %>%
  mutate_if(is.factor, fct_drop)
test_exp <- mutate_all(test_exp, list(~na_if(.,""))) %>%
  mutate_if(is.factor, fct_drop)

# look into fct_lump (Collapsing the least/most frequent values of a factor into “other”) --> or step_other in recipe
# employment_industry, employment_occupation
sort(summary(train_full$hhs_geo_region)/nrow(train_full))
sort(summary(train_full$employment_industry)/nrow(train_full))
sort(summary(train_full$employment_occupation)/nrow(train_full))

# predictors w/ most missing values
# employment_occupation, employment_industry, health_insurance all around 50%
# income_poverty around 16%
p_missing <- unlist(lapply(train_full, function(x) sum(is.na(x))))/nrow(train_full)
sort(p_missing[p_missing > 0], decreasing = TRUE)

# many observations are missing all three
train_full %>%
  select(employment_occupation, employment_industry, health_insurance) %>%
  gg_miss_upset()

# highest proportion of no health insurance is among NAs
ggplot(train_full, aes(x = employment_occupation)) + 
  geom_bar(aes(fill = as.factor(health_insurance))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment occupation", y = "", fill = "Has health insurance")

# variation in having insurance among occupation
ggplot(drop_na(train_full, employment_occupation), aes(x = employment_occupation)) + 
  geom_bar(aes(fill = as.factor(health_insurance))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment occupation", y = "", fill = "Has health insurance")

# highest proportion of no health insurance is among NAs
ggplot(train_full, aes(x = employment_industry)) + 
  geom_bar(aes(fill = as.factor(health_insurance))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment industry", y = "", fill = "Has health insurance")

# variation in having insurance among industry
ggplot(drop_na(train_full, employment_industry), aes(x = employment_industry)) + 
  geom_bar(aes(fill = as.factor(health_insurance))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment industry", y = "", fill = "Has health insurance")

# most are NA in both industry and occupation
ggplot(train_full, aes(x = employment_industry)) + 
  geom_bar(aes(fill = as.factor(employment_occupation))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment industry", y = "", fill = "Employment occupation")

# more variation of occupation within industry than I expected, but some noticeable patterns
ggplot(drop_na(train_full, employment_industry), aes(x = employment_industry)) + 
  geom_bar(aes(fill = as.factor(employment_occupation))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment industry", y = "", fill = "Employment occupation")

# need to think through the best way to use / impute for / drop employment_industry, employment_occupation, health_insurance
# can I model each?
# how to determine which predictors are most correlated w/ these three?

# probably not
# emp_ind_mn <- multinom(employment_industry ~ . , data = subset(train_full, select = -c(h1n1_vaccine, seasonal_vaccine, respondent_id)))

#z <- summary(emp_ind_mn)$coefficients/summary(emp_ind_mn)$standard.errors
#p <- (1 - pnorm(abs(z), 0, 1)) * 2

health_ins_lg <- glm(as.factor(health_insurance) ~ . , family = "binomial", data = subset(train_full, select = -c(h1n1_vaccine, seasonal_vaccine, respondent_id, employment_industry, employment_occupation)))
summary(health_ins_lg)
# interesting
health_ins_pred <- predict(health_ins_lg, filter(train_full, is.na(health_insurance)), type = "response")
```

```{r data manipulation}
# transform categorical to numerical for certain algorithms
train_full_num <- train_full %>% mutate_if(is.factor, as.numeric) # could also do as.integer
```

```{r clustering experiment on high NAs}
train_clus_empind <- train_full_num %>%
  filter(is.na(employment_industry)) %>%
  select(-c(h1n1_vaccine, seasonal_vaccine, respondent_id, employment_industry, employment_occupation)) %>%
  drop_na()
  
emp_ind_km3 <- kmeans(train_clus_empind, centers=3, nstart=10)

# LOL, so much overlap
# https://www.datanovia.com/en/blog/k-means-clustering-visualization-in-r-step-by-step-guide/
fviz_cluster(emp_ind_km3, data = train_clus_empind,
             palette = c("#2E9FDF", "#00AFBB", "#E7B800"), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw()
             )

emp_ind_km5 <- kmeans(train_clus_empind, centers=5, nstart=25)

# still a lot of overlap
fviz_cluster(emp_ind_km5, data = train_clus_empind,
             #palette = c("#2E9FDF", "#00AFBB", "#E7B800"), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw()
             )

emp_ind_km10 <- kmeans(train_clus_empind, centers=10, nstart=50)

# simply not a good idea
fviz_cluster(emp_ind_km10, data = train_clus_empind,
             #palette = c("#2E9FDF", "#00AFBB", "#E7B800"), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw()
             )

emp_ind_km20 <- kmeans(train_clus_empind, centers=20, nstart=100)

# simply not a good idea
fviz_cluster(emp_ind_km20, data = train_clus_empind,
             #palette = c("#2E9FDF", "#00AFBB", "#E7B800"), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw()
             )

# new idea: do fct_lump and then try clustering
```
```{r transforming high NAs}
# many observations are missing all three
train_full %>%
  select(employment_occupation, employment_industry, health_insurance) %>%
  gg_miss_upset()

# similar between train and test data
test_exp %>%
  select(employment_occupation, employment_industry, health_insurance) %>%
  gg_miss_upset()

mcar_test(train_full)

# create new factor levels based on groupings w/ highest NAs from plot above
# (1) employment_occupation and employment_industry both NA
# (2) employment_occupation, employment_industry, and health_insurance all NA
# (3) health_insurance NA but not employment_occupation or employment_industry
train_full_tr <- train_full %>%
  mutate(employment_occupation = fct_expand(employment_occupation, "na_all", "na_emp"), employment_industry = fct_expand(employment_industry, "na_all", "na_emp"), health_insurance = fct_expand(as.factor(health_insurance), "na_all", "na_ins"))

summary(train_full_tr)

train_full_tr <- train_full_tr %>%
  mutate(across(c(employment_occupation, employment_industry, health_insurance), function(x) replace(x, is.na(employment_occupation) & is.na(employment_industry) & is.na(health_insurance), "na_all")),
         across(c(employment_occupation, employment_industry), function(x) replace(x, is.na(employment_occupation) & is.na(employment_industry), "na_emp")),
         health_insurance = replace(health_insurance, is.na(health_insurance) & !is.na(employment_occupation) & !is.na(employment_industry), "na_ins"))

# remaining NA totals in three varbs matches what was expected from plot above
summary(train_full_tr)

miss_var_summary(train_full)
miss_var_summary(train_full_tr) # <1% NAs across all three now

# apply to test_exp
test_exp_tr <- test_exp %>%
  mutate(employment_occupation = fct_expand(employment_occupation, "na_all", "na_emp"), employment_industry = fct_expand(employment_industry, "na_all", "na_emp"), health_insurance = fct_expand(as.factor(health_insurance), "na_all", "na_ins"))

test_exp_tr <- test_exp_tr %>%
  mutate(across(c(employment_occupation, employment_industry, health_insurance), function(x) replace(x, is.na(employment_occupation) & is.na(employment_industry) & is.na(health_insurance), "na_all")),
         across(c(employment_occupation, employment_industry), function(x) replace(x, is.na(employment_occupation) & is.na(employment_industry), "na_emp")),
         health_insurance = replace(health_insurance, is.na(health_insurance) & !is.na(employment_occupation) & !is.na(employment_industry), "na_ins"))

# look into other features of naniar
```

### `tidymodels` workflow
#### starting from (00) as baseline
```{r}
# https://www.rebeccabarter.com/blog/2020-03-25_machine_learning/
# class imbalance walkthrough: https://juliasilge.com/blog/himalayan-climbing/
# to try (abbreviated from original below):
# (00) use train_full_tr (created new NA categories based on patterns across 3 varbs w/ most missing data), leave off normalization, try knn and mode imputation --> try w/ this as new baseline [(4), (5), (6)]
# (4) try step_smote() on h1n1_vaccine to address class imbalance -- apply SMOTE algorithm to "generate new examples of the minority class using nearest neighbors of these cases" https://themis.tidymodels.org/reference/step_smote.html
# (5) try other classification methods: boost_tree (xgboost), some discriminant model (discrim_regularized?), single layer neural network / mlp, multinom_reg (nnet, glmnet), nearest_neighbor (kknn)
# (6) try predicting either h1n1_vaccine or seasonal_vaccine first (w/ full dataset that includes the other as a predictor) and then attaching those predictions to the test_exp dataset --> try this w/ (0) random forest

# split full training set into training and testing
# try adding strata argument for h1n1_vaccine split
set.seed(4242)
# (00) using transformed high NA dataset
flu_split <- initial_split(train_full_tr, prop = 0.8)

# extract training and testing sets
flu_train <- training(flu_split)
flu_test <- testing(flu_split)

# create CV object from training data
# specify v = 5 (instead of default 10)?
# might consider setting strata = h1n1_vaccine to address class imbalance
flu_cv <- vfold_cv(flu_train, v = 5)

# define the recipe
### pick up later: need to rename this b/c different 
### from original _00 recipes
# (00)
H1N1_recipe_00_dum <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(h1n1_vaccine ~ ., 
         data = train_full_tr) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "seasonal_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  #step_integer(all_nominal_predictors())
  step_dummy(all_nominal_predictors())

seasonal_recipe_00_dum <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(seasonal_vaccine ~ ., 
         data = train_full_tr) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "h1n1_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  #step_integer(all_nominal_predictors())
  step_dummy(all_nominal_predictors())
```

```{r tidymodels boosted trees}
# looking to https://juliasilge.com/blog/xgboost-tune-volleyball/
# https://www.r-bloggers.com/2020/05/using-xgboost-with-tidymodels/
# define the xgboost model
# could add to set_engine: objective = "binary:logistic"
# if change set_mode to "regression" (I think)
xgboost_model <- 
  boost_tree() %>%
  set_args(trees = 1000,
  tree_depth = tune(), min_n = tune(), 
  loss_reduction = tune(), # first three: model complexity
  sample_size = tune(), mtry = tune(), # randomness
  learn_rate = tune()) %>% # step size
  set_engine("xgboost", event_level = "second") %>% 
  set_mode("classification")

# set the workflow
xgb_workflow_H1N1 <- workflow() %>%
  add_recipe(H1N1_recipe_00_dum) %>%
  add_model(xgboost_model)

xgb_workflow_seasonal <- workflow() %>%
  add_recipe(seasonal_recipe_00_dum) %>%
  add_model(xgboost_model)

# parameter tuning
# grid specification
#xgboost_params <- 
  #parameters(
    #min_n(),
    #tree_depth(),
    #learn_rate(),
    #loss_reduction()
  #)

xgboost_grid <- 
  grid_max_entropy(
    tree_depth(),
    min_n(),
    loss_reduction(),
    sample_size = sample_prop(),
    finalize(mtry(), flu_train),
    learn_rate(),
    size = 10
  )

set.seed(6767)
# only takes ~40 minutes!
xgb_tune_results_H1N1 <- xbg_workflow_H1N1 %>%
  tune_grid(resamples = flu_cv, #CV object
            grid = xgboost_grid, # grid of values to try
            control = control_grid(parallel_over = "resamples")
            )

# need to adjust recipe to transform factor predictors to dummy varbs --> step_dummy
# xgb_tune_results$.notes[[1]][[1]]

set.seed(5656)
# only takes ~40 minutes!
xgb_tune_results_seasonal <- xbg_workflow_seasonal %>%
  tune_grid(resamples = flu_cv, #CV object
            grid = xgboost_grid, # grid of values to try
            control = control_grid(parallel_over = "resamples")
            )

# finalize workflow
param_xgb_H1N1 <- xgb_tune_results_H1N1 %>%
  select_best(metric = "roc_auc")

xgb_workflow_H1N1 <- xgb_workflow_H1N1 %>%
  finalize_workflow(param_xgb_H1N1)

# same as H1N1
param_xgb_seasonal <- xgb_tune_results_seasonal %>%
  select_best(metric = "roc_auc")

xgb_workflow_seasonal <- xgb_workflow_seasonal %>%
  finalize_workflow(param_xgb_H1N1)

# variable importance graph
library(vip)

# top 3: doctor_recc_h1n1 (>0.20), opinion_h1n1_risk, opinion_h1n1_vacc_effective (between 0.10-0.15)
xgb_workflow_H1N1 %>%
  fit(data = flu_train) %>%
  extract_fit_parsnip() %>%
  vip(geom = "point")
```

```{r tidymodels boosted trees eval}
# evaluate model on "test" set
# (00) + dummy varbs + initial xgboost model
xgb_fit_H1N1 <- xbg_workflow_H1N1 %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

## need to compare to csv file; seem high/good
test_performance_xgb_H1N1 <- xgb_fit_H1N1 %>% collect_metrics()
write_csv(test_performance_xgb_H1N1, "test_performance_xgb_H1N1.csv")

xgb_fit_seasonal <- xgb_workflow_seasonal %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

## need to compare to csv file; seem high/good
test_performance_xgb_seasonal <- xgb_fit_seasonal %>% collect_metrics()

# generate predictions from the test set
# (00) + initial xgboost model
test_predictions_xgb_H1N1 <- xgb_fit_H1N1 %>% collect_predictions()

test_predictions_xgb_seasonal <- xgb_fit_seasonal %>% collect_predictions()
write_csv(test_predictions_xgb_seasonal, "test_predictions_xgb_seasonal.csv")
```

```{r model fitting and prediction}
# random forest
# (00)
final_model_rf_H1N1_00 <- fit(rf_workflow_H1N1_00, train_full_tr)

rf_pred_H1N1_00 <- predict(final_model_rf_H1N1_00, new_data = data.frame(test_exp_tr, seasonal_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

final_model_rf_seasonal_00 <- fit(rf_workflow_seasonal_00, train_full_tr)

rf_pred_seasonal_00 <- predict(final_model_rf_seasonal_00, new_data = data.frame(test_exp_tr, h1n1_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

# xgboost
# (00) + dummy varbs
## look into: "WARNING: amalgamation/../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
final_model_xgb_H1N1_00_dum <- fit(xgb_workflow_H1N1, train_full_tr)

xgb_pred_H1N1_00_dum <- predict(final_model_xgb_H1N1_00_dum, new_data = data.frame(test_exp_tr, seasonal_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

## look into same warning
final_model_xgb_seasonal_00_dum <- fit(xgb_workflow_seasonal, train_full_tr)

xgb_pred_seasonal_00_dum <- predict(final_model_xgb_seasonal_00_dum, new_data = data.frame(test_exp_tr, h1n1_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")
```

```{r submissions 00}
# random forest
# (00)
rf_pred_00 <- bind_cols(respondent_id = test_exp_tr$respondent_id, h1n1_vaccine = rf_pred_H1N1_00$.pred_1, seasonal_vaccine = rf_pred_seasonal_00$.pred_1)

# 0.8528 --> best so far!
# now top 14% ;)
write_csv(rf_pred_00, "rf_00_tidymodels_pred.csv")

# xgboost
# (00) + dummy varbs
xgb_pred_00_dum <- bind_cols(respondent_id = test_exp_tr$respondent_id, h1n1_vaccine = xgb_pred_H1N1_00_dum$.pred_1, seasonal_vaccine = xgb_pred_seasonal_00_dum$.pred_1)

# 0.8572 --> best so far
# now top 12%
write_csv(xgb_pred_00_dum, "xgb_00_dum_tidymodels_pred.csv")
```

#### starting from (0) as baseline, random forest and logistic regression, close to tidymodels walkthrough
```{r tidymodels setup}
# https://www.rebeccabarter.com/blog/2020-03-25_machine_learning/
# class imbalance walkthrough: https://juliasilge.com/blog/himalayan-climbing/
# to try:
# (00) use train_full_tr (created new NA categories based on patterns across 3 varbs w/ most missing data), leave off normalization, try knn and mode imputation --> try w/ this as new baseline [(4), (5), (6)]
# (0) random forest and logistic regression, close to tidymodels walkthrough (already done)
# (1) step_nzv
# (2) collapsing the least/most frequent values of a factor into “other”
# (3) trying with transformation of all explanatories to numeric (w/ normalization) -- step_integer(all_nominal_predictors())
# (4) try step_smote() on h1n1_vaccine to address class imbalance -- apply SMOTE algorithm to "generate new examples of the minority class using nearest neighbors of these cases" https://themis.tidymodels.org/reference/step_smote.html
# (5) try other classification methods: boost_tree (xgboost), some discriminant model (discrim_regularized?), single layer neural network / mlp, multinom_reg (nnet, glmnet), nearest_neighbor (kknn)
# (6) try predicting either h1n1_vaccine or seasonal_vaccine first (w/ full dataset that includes the other as a predictor) and then attaching those predictions to the test_exp dataset --> try this w/ (0) random forest
# (7) drop normalization? just to see? --> went ahead and did it w/ (00)

# split full training set into training and testing
# try adding strata argument for h1n1_vaccine split
set.seed(4242)
#flu_split <- initial_split(train_full, prop = 0.8)
# (00) using transformed high NA dataset
flu_split <- initial_split(train_full_tr, prop = 0.8)
flu_split

# extract training and testing sets
flu_train <- training(flu_split)
flu_test <- testing(flu_split)

# create CV object from training data
# specify v = 5 (instead of default 10)?
# might consider setting strata = h1n1_vaccine to address class imbalance
flu_cv <- vfold_cv(flu_train, v = 5)

# define the recipe
# (00)
H1N1_recipe_00 <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(h1n1_vaccine ~ ., 
         data = train_full_tr) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "seasonal_vaccine")) %>%
  step_impute_knn(all_predictors())

seasonal_recipe_00 <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(seasonal_vaccine ~ ., 
         data = train_full_tr) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "h1n1_vaccine")) %>%
  step_impute_knn(all_predictors())

# (0)
# try adding step_nzv() to end
H1N1_recipe <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(h1n1_vaccine ~ ., 
         data = train_full) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "seasonal_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_normalize(all_numeric())

seasonal_recipe <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(seasonal_vaccine ~ ., 
         data = train_full) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "h1n1_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_normalize(all_numeric())

# (1) step_nzv
H1N1_recipe_nzv <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(h1n1_vaccine ~ ., 
         data = train_full) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "seasonal_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_normalize(all_numeric()) %>%
  step_nzv(all_predictors())

seasonal_recipe_nzv <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(seasonal_vaccine ~ ., 
         data = train_full) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "h1n1_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_normalize(all_numeric()) %>%
  step_nzv(all_predictors())

# (2) step_other
H1N1_recipe_oth <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(h1n1_vaccine ~ ., 
         data = train_full) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "seasonal_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_other(employment_industry, employment_occupation) %>%
  step_normalize(all_numeric())

seasonal_recipe_oth <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(seasonal_vaccine ~ ., 
         data = train_full) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "h1n1_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_other(employment_industry, employment_occupation) %>%
  step_normalize(all_numeric()) 

# (3) all integers
H1N1_recipe_int <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(h1n1_vaccine ~ ., 
         data = train_full) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "seasonal_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_integer(all_nominal_predictors()) %>%
  step_normalize(all_numeric())

seasonal_recipe_int <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(seasonal_vaccine ~ ., 
         data = train_full) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "h1n1_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_integer(all_nominal_predictors()) %>%
  step_normalize(all_numeric()) 

# (4) SMOTE -- haven't finished this
H1N1_recipe_int <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(h1n1_vaccine ~ ., 
         data = train_full) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "seasonal_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_integer(all_nominal_predictors()) %>%
  step_normalize(all_numeric())

seasonal_recipe_int <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(seasonal_vaccine ~ ., 
         data = train_full) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "h1n1_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_integer(all_nominal_predictors()) %>%
  step_normalize(all_numeric()) 

# just for kicks
# (00)
H1N1_train_preprocessed <- H1N1_recipe %>%
  prep(flu_train) %>%
  juice()
H1N1_train_preprocessed

# (0)
H1N1_train_preprocessed <- H1N1_recipe %>%
  # apply the recipe to the training data
  prep(flu_train) %>%
  # extract the pre-processed training dataset
  juice()
H1N1_train_preprocessed

# (1) step_nzv
# only drops behavioral_antiviral_meds, lol
H1N1_train_preprocessed_nzv <- H1N1_recipe_nzv %>%
  # apply the recipe to the training data
  prep(flu_train) %>%
  # extract the pre-processed training dataset
  juice()

# (2) step_other
H1N1_train_preprocessed_oth <- H1N1_recipe_oth %>%
  # apply the recipe to the training data
  prep(flu_train) %>%
  # extract the pre-processed training dataset
  juice()

# cool!
summary(H1N1_train_preprocessed_oth$employment_industry)
summary(H1N1_train_preprocessed_oth$employment_occupation)
summary(H1N1_train_preprocessed_oth$hhs_geo_region)

# (3) step_other
H1N1_train_preprocessed_int <- H1N1_recipe_int %>%
  # apply the recipe to the training data
  prep(flu_train) %>%
  # extract the pre-processed training dataset
  juice()

summary(H1N1_train_preprocessed_int)

# look into step_other() for employment_industry, employment_occupation
# default threshold is 0.05
sort(summary(H1N1_train_preprocessed$employment_industry))/nrow(H1N1_train_preprocessed)
sort(summary(H1N1_train_preprocessed$employment_occupation))/nrow(H1N1_train_preprocessed)
```

```{r tidymodels random forest}
# specify the model
# random forest
rf_model_H1N1 <- 
  # specify that the model is a random forest
  rand_forest() %>%
  # specify that the `mtry` parameter needs to be tuned
  #set_args(mtry = tune(), trees = tune()) %>%
  set_args(mtry = tune()) %>%
  # select the engine/package that underlies the model
  set_engine("ranger", importance = "permutation") %>%
  # choose either the continuous regression or binary classification mode
  set_mode("classification") 

# could have done this in the first place
rf_model_flu <- rf_model_H1N1

# (00)
# set the workflow
rf_workflow_H1N1_00 <- workflow() %>%
  # add the recipe
  add_recipe(H1N1_recipe_00) %>%
  # add the model
  add_model(rf_model_H1N1)

rf_workflow_seasonal_00 <- workflow() %>%
  # add the recipe
  add_recipe(seasonal_recipe_00) %>%
  # add the model
  add_model(rf_model_flu)

# (0)
# set the workflow
rf_workflow_H1N1 <- workflow() %>%
  # add the recipe
  add_recipe(H1N1_recipe) %>%
  # add the model
  add_model(rf_model_H1N1)

rf_workflow_seasonal <- workflow() %>%
  # add the recipe
  add_recipe(seasonal_recipe) %>%
  # add the model
  add_model(rf_model_flu)

# (1) step_nzv
rf_workflow_H1N1_nzv <- workflow() %>%
  # add the recipe
  add_recipe(H1N1_recipe_nzv) %>%
  # add the model
  add_model(rf_model_H1N1)

rf_workflow_seasonal_nzv <- workflow() %>%
  # add the recipe
  add_recipe(seasonal_recipe_nzv) %>%
  # add the model
  add_model(rf_model_flu)

# (2) step_other
rf_workflow_H1N1_oth <- workflow() %>%
  # add the recipe
  add_recipe(H1N1_recipe_oth) %>%
  # add the model
  add_model(rf_model_H1N1)

rf_workflow_seasonal_oth <- workflow() %>%
  # add the recipe
  add_recipe(seasonal_recipe_oth) %>%
  # add the model
  add_model(rf_model_flu)

# (3) all integers
rf_workflow_H1N1_int <- workflow() %>%
  # add the recipe
  add_recipe(H1N1_recipe_int) %>%
  # add the model
  add_model(rf_model_H1N1)

rf_workflow_seasonal_int <- workflow() %>%
  # add the recipe
  add_recipe(seasonal_recipe_int) %>%
  # add the model
  add_model(rf_model_flu)

# parameter tuning
param_tune <- c(round(sqrt(ncol(train_full[,-c(1:3)])))-1, 
                round(sqrt(ncol(train_full[,-c(1:3)]))),
                round(sqrt(ncol(train_full[,-c(1:3)])))+1)

# specify which values want to try
#rf_grid <- expand.grid(mtry = param_tune, trees = c(100, 500))
rf_grid <- expand.grid(mtry = param_tune)

# (00)
# extract results
rf_tune_results_H1N1_00 <- rf_workflow_H1N1_00 %>%
  tune_grid(resamples = flu_cv, # CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(accuracy, roc_auc) # metrics
            #metrics = metric_set(roc_auc)
            )

rf_tune_results_seasonal_00 <- rf_workflow_seasonal_00 %>%
  tune_grid(resamples = flu_cv, # CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(accuracy, roc_auc) # metrics
            )

# finalize workflow
param_final_H1N1_00 <- rf_tune_results_H1N1_00 %>%
  select_best(metric = "roc_auc") # mtry = 5

#rf_workflow_H1N1_00 <- rf_workflow_H1N1_00 %>%
  #finalize_workflow(as_tibble_row(c(mtry = 5)))

rf_workflow_H1N1_00 <- rf_workflow_H1N1_00 %>%
  finalize_workflow(param_final_H1N1_00)

param_final_seasonal_00 <- rf_tune_results_seasonal_00 %>%
  select_best(metric = "roc_auc") # mtry = 5

#rf_workflow_seasonal_00 <- rf_workflow_seasonal_00 %>%
  #finalize_workflow(as_tibble_row(c(mtry = 5)))

rf_workflow_seasonal_00 <- rf_workflow_seasonal_00 %>%
  finalize_workflow(param_final_seasonal_00)

# (0)
# extract results
# took about an hour, could adjust CV object
rf_tune_results_H1N1 <- rf_workflow_H1N1 %>%
  tune_grid(resamples = flu_cv, # CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(accuracy, roc_auc) # metrics we care about
            #metrics = metric_set(roc_auc)
            )

rf_tune_results_seasonal <- rf_workflow_seasonal %>%
  tune_grid(resamples = flu_cv, # CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(accuracy, roc_auc) # metrics we care about
            #metrics = metric_set(roc_auc)
            )

# print results
rf_tune_results_H1N1 %>%
  collect_metrics()

rf_tune_results_seasonal %>%
  collect_metrics()

# finalize workflow
param_final_H1N1 <- rf_tune_results_H1N1 %>%
  select_best(metric = "roc_auc")
param_final_H1N1 # mtry = 6

rf_workflow_H1N1 <- rf_workflow_H1N1 %>%
  finalize_workflow(param_final_H1N1)

param_final_seasonal <- rf_tune_results_seasonal %>%
  select_best(metric = "roc_auc")
param_final_seasonal # mtry = 5

rf_workflow_seasonal <- rf_workflow_seasonal %>%
  finalize_workflow(param_final_seasonal)

# (1) step_nzv
# stick with mtry values from (0)
rf_workflow_H1N1_nzv <- rf_workflow_H1N1_nzv %>%
  finalize_workflow(as_tibble_row(c(mtry = 6)))

rf_workflow_seasonal_nzv <- rf_workflow_seasonal_nzv %>%
  finalize_workflow(as_tibble_row(c(mtry = 5)))

# (2) step_other
# stick with mtry values from (0)
rf_workflow_H1N1_oth <- rf_workflow_H1N1_oth %>%
  finalize_workflow(as_tibble_row(c(mtry = 6)))

rf_workflow_seasonal_oth <- rf_workflow_seasonal_oth %>%
  finalize_workflow(as_tibble_row(c(mtry = 5)))

# (3) all integers
# extract results
rf_tune_results_H1N1_int <- rf_workflow_H1N1_int %>%
  tune_grid(resamples = flu_cv, # CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(accuracy, roc_auc) # metrics
            #metrics = metric_set(roc_auc)
            )

rf_tune_results_seasonal_int <- rf_workflow_seasonal_int %>%
  tune_grid(resamples = flu_cv, # CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(accuracy, roc_auc) # metrics
            )

# finalize workflow
param_final_H1N1_int <- rf_tune_results_H1N1_int %>%
  select_best(metric = "roc_auc") # mtry = 5

rf_workflow_H1N1_int <- rf_workflow_H1N1_int %>%
  finalize_workflow(param_final_H1N1_int)

#rf_workflow_H1N1_int <- rf_workflow_H1N1_int %>%
  #finalize_workflow(as_tibble_row(c(mtry = 5)))

param_final_seasonal_int <- rf_tune_results_seasonal_int %>%
  select_best(metric = "roc_auc") # mtry = 5

rf_workflow_seasonal_int <- rf_workflow_seasonal_int %>%
  finalize_workflow(param_final_seasonal_int)

#rf_workflow_seasonal_int <- rf_workflow_seasonal_int %>%
  #finalize_workflow(as_tibble_row(c(mtry = 5)))

# (00)
# evaluate model on "test" set
rf_fit_H1N1_00 <- rf_workflow_H1N1_00 %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

# better than (3) [need to check against others]
test_performance_rf_H1N1_00 <- rf_fit_H1N1_00 %>% collect_metrics()

rf_fit_seasonal_00 <- rf_workflow_seasonal_00 %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

# slightly better than (3) [need to check against others]
test_performance_rf_seasonal_00 <- rf_fit_seasonal_00 %>% collect_metrics()

# (0)
# evaluate model on "test" set
rf_fit_H1N1 <- rf_workflow_H1N1 %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

test_performance_rf_H1N1 <- rf_fit_H1N1 %>% collect_metrics()
test_performance_rf_H1N1

rf_fit_seasonal <- rf_workflow_seasonal %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

test_performance_rf_seasonal <- rf_fit_seasonal %>% collect_metrics()
test_performance_rf_seasonal

# (1) step_nzv
rf_fit_H1N1_nzv <- rf_workflow_H1N1_nzv %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

# slightly better than (0)
test_performance_rf_H1N1_nzv <- rf_fit_H1N1_nzv %>% collect_metrics()

rf_fit_seasonal_nzv <- rf_workflow_seasonal_nzv %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

# slightly better than (0)
test_performance_rf_seasonal_nzv <- rf_fit_seasonal_nzv %>% collect_metrics()

# (2) step_other
rf_fit_H1N1_oth <- rf_workflow_H1N1_oth %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

# slightly worse than (0) and (1)
test_performance_rf_H1N1_oth <- rf_fit_H1N1_oth %>% collect_metrics()

rf_fit_seasonal_oth <- rf_workflow_seasonal_oth %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

# slightly worse than (0) and (1)
test_performance_rf_seasonal_oth <- rf_fit_seasonal_oth %>% collect_metrics()

# (3) all integers
rf_fit_H1N1_int <- rf_workflow_H1N1_int %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

# better than previous? (need to rerun earlier models)
test_performance_rf_H1N1_int <- rf_fit_H1N1_int %>% collect_metrics()

rf_fit_seasonal_int <- rf_workflow_seasonal_int %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

# better than previous? (need to rerun earlier models)
test_performance_rf_seasonal_int <- rf_fit_seasonal_int %>% collect_metrics()

# (00)
test_predictions_rf_H1N1_00 <- rf_fit_H1N1_00 %>% collect_predictions()

test_predictions_rf_seasonal_00 <- rf_fit_seasonal_00 %>% collect_predictions()

# (0)
# generate predictions from the test set
test_predictions_rf_H1N1 <- rf_fit_H1N1 %>% collect_predictions()
test_predictions_rf_H1N1

test_predictions_rf_seasonal <- rf_fit_seasonal %>% collect_predictions()
test_predictions_rf_seasonal

# (1) step_nzv
test_predictions_rf_H1N1_nzv <- rf_fit_H1N1_nzv %>% collect_predictions()

test_predictions_rf_seasonal_nzv <- rf_fit_seasonal_nzv %>% collect_predictions()

# (2) step_other
test_predictions_rf_H1N1_oth <- rf_fit_H1N1_oth %>% collect_predictions()

test_predictions_rf_seasonal_oth <- rf_fit_seasonal_oth %>% collect_predictions()

# (3) all integers
test_predictions_rf_H1N1_int <- rf_fit_H1N1_int %>% collect_predictions()

test_predictions_rf_seasonal_int <- rf_fit_seasonal_int %>% collect_predictions()

# (0)
# generate a confusion matrix
# most of true 1s predicted as 0s
rf_cm_H1N1 <- test_predictions_rf_H1N1 %>% 
  conf_mat(truth = h1n1_vaccine, estimate = .pred_class)
rf_cm_H1N1
autoplot(rf_cm_H1N1, type = "mosaic")

test_predictions_rf_H1N1 %>%
  ggplot() +
  geom_density(aes(x = .pred_1, fill = h1n1_vaccine), 
               alpha = 0.5)

# not bad!
test_predictions_rf_seasonal %>% 
  conf_mat(truth = seasonal_vaccine, estimate = .pred_class)
```

```{r tidymodels logistic regression}
# specify the model
# logistic regression
lr_model_H1N1 <- 
  # specify that the model is a logistic regression
  logistic_reg() %>%
  # select the engine/package that underlies the model
  set_engine("glm") %>%
  # choose either the continuous regression or binary classification mode
  set_mode("classification") 

lr_model_flu <- lr_model_H1N1

# set the workflow
lr_workflow_H1N1 <- workflow() %>%
  # add the recipe
  add_recipe(H1N1_recipe) %>%
  # add the model
  add_model(lr_model_flu)

lr_workflow_seasonal <- workflow() %>%
  # add the recipe
  add_recipe(seasonal_recipe) %>%
  # add the model
  add_model(lr_model_flu)

# can do parameter tuning? regularization like in benchmark?
# think I'd need to use glmnet
# https://compgenomr.github.io/book/logistic-regression-and-regularization.html

# evaluate model on "test" set
lr_fit_H1N1 <- lr_workflow_H1N1 %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split, metrics = metric_set(accuracy, roc_auc))

test_performance_lr_H1N1 <- lr_fit_H1N1 %>% collect_metrics()
test_performance_lr_H1N1

lr_fit_seasonal <- lr_workflow_seasonal %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split, metrics = metric_set(accuracy, roc_auc))

test_performance_lr_seasonal <- lr_fit_seasonal %>% collect_metrics()
test_performance_lr_seasonal

# generate predictions from the test set
test_predictions_lr_H1N1 <- lr_fit_H1N1 %>% collect_predictions()
test_predictions_lr_H1N1

test_predictions_lr_seasonal <- lr_fit_seasonal %>% collect_predictions()
test_predictions_lr_seasonal

# generate a confusion matrix
# like random forest, most of true 1s predicted as 0s
test_predictions_lr_H1N1 %>% 
  conf_mat(truth = h1n1_vaccine, estimate = .pred_class)

test_predictions_lr_seasonal %>% 
  conf_mat(truth = seasonal_vaccine, estimate = .pred_class)
```

```{r tidymodels other models}
# try other classification models
# https://www.tidymodels.org/find/parsnip/
```

```{r comparing test performance metrics}
# overall comparison of test performance
# test_performance_rf_H1N1_int <- read_csv("test_performance_H1N1.csv")
# test_performance_H1N1 <- bind_rows(test_performance_rf_H1N1_int, tibble(test_performance_rf_H1N1_00, model = "rf_00"))
# need to redo (00) at some point now that recipe corrected
test_performance_H1N1 <- bind_rows(tibble(test_performance_rf_H1N1, model = "rf"), tibble(test_performance_lr_H1N1, model = "lr"), tibble(test_performance_rf_H1N1_nzv, model = "rf_nzv"), tibble(test_performance_rf_H1N1_oth, model = "rf_oth"), tibble(test_performance_rf_H1N1_int, model = "rf_int"), tibble(test_performance_rf_H1N1_00, model = "rf_00"))

write_csv(test_performance_H1N1, "test_performance_H1N1.csv")

# need to redo (00) at some point now that recipe corrected
# test_performance_rf_seasonal_int <- read_csv("test_performance_seasonal.csv")
# test_performance_seasonal <- bind_rows(test_performance_rf_seasonal_int, tibble(test_performance_rf_seasonal_00, model = "rf_00"))
test_performance_seasonal <- bind_rows(tibble(test_performance_rf_seasonal, model = "rf"), tibble(test_performance_lr_seasonal, model = "lr"), tibble(test_performance_rf_seasonal_nzv, model = "rf_nzv"), tibble(test_performance_rf_seasonal_oth, model = "rf_oth"), tibble(test_performance_rf_seasonal_int, model = "rf_int"), tibble(test_performance_rf_seasonal_00, model = "rf_00"))

write_csv(test_performance_seasonal, "test_performance_seasonal.csv")
```

```{r tidymodels flu model fitting}
# random forest
# (00)
final_model_rf_H1N1_00 <- fit(rf_workflow_H1N1_00, train_full_tr)

rf_pred_H1N1_00 <- predict(final_model_rf_H1N1_00, new_data = data.frame(test_exp_tr, seasonal_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

final_model_rf_seasonal_00 <- fit(rf_workflow_seasonal_00, train_full_tr)

rf_pred_seasonal_00 <- predict(final_model_rf_seasonal_00, new_data = data.frame(test_exp_tr, h1n1_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

# (0)
# fitting and using final model
final_model_rf_H1N1 <- fit(rf_workflow_H1N1, train_full)
final_model_rf_H1N1

rf_pred_H1N1 <- predict(final_model_rf_H1N1, new_data = data.frame(test_exp, seasonal_vaccine = as.factor(rep(0, nrow(test_exp)))), type = "prob")
# add seasonal_vaccine 0 vector so dataframe has same structure
# (so that it can be dropped in recipe)

final_model_rf_seasonal <- fit(rf_workflow_seasonal, train_full)
final_model_rf_seasonal

rf_pred_seasonal <- predict(final_model_rf_seasonal, new_data = data.frame(test_exp, h1n1_vaccine = as.factor(rep(0, nrow(test_exp)))), type = "prob")
# add h1n1_vaccine 0 vector so dataframe has same structure
# (so that it can be dropped in recipe)

# (1) step_nzv
final_model_rf_H1N1_nzv <- fit(rf_workflow_H1N1_nzv, train_full)

rf_pred_H1N1_nzv <- predict(final_model_rf_H1N1_nzv, new_data = data.frame(test_exp, seasonal_vaccine = as.factor(rep(0, nrow(test_exp)))), type = "prob")

final_model_rf_seasonal_nzv <- fit(rf_workflow_seasonal_nzv, train_full)

rf_pred_seasonal_nzv <- predict(final_model_rf_seasonal_nzv, new_data = data.frame(test_exp, h1n1_vaccine = as.factor(rep(0, nrow(test_exp)))), type = "prob")

# (2) step_oth
final_model_rf_H1N1_oth <- fit(rf_workflow_H1N1_oth, train_full)

rf_pred_H1N1_oth <- predict(final_model_rf_H1N1_oth, new_data = data.frame(test_exp, seasonal_vaccine = as.factor(rep(0, nrow(test_exp)))), type = "prob")

final_model_rf_seasonal_oth <- fit(rf_workflow_seasonal_oth, train_full)

rf_pred_seasonal_oth <- predict(final_model_rf_seasonal_oth, new_data = data.frame(test_exp, h1n1_vaccine = as.factor(rep(0, nrow(test_exp)))), type = "prob")

# (3) all integers
final_model_rf_H1N1_int <- fit(rf_workflow_H1N1_int, train_full)

rf_pred_H1N1_int <- predict(final_model_rf_H1N1_int, new_data = data.frame(test_exp, seasonal_vaccine = as.factor(rep(0, nrow(test_exp)))), type = "prob")

final_model_rf_seasonal_int <- fit(rf_workflow_seasonal_int, train_full)

rf_pred_seasonal_int <- predict(final_model_rf_seasonal_int, new_data = data.frame(test_exp, h1n1_vaccine = as.factor(rep(0, nrow(test_exp)))), type = "prob")

# (0)
# variable importance
ranger_obj_H1N1 <- extract_fit_parsnip(final_model_rf_H1N1)$fit
ranger_obj_H1N1
sort(ranger_obj_H1N1$variable.importance, decreasing = TRUE)

ranger_obj_seasonal <- extract_fit_parsnip(final_model_rf_seasonal)$fit
ranger_obj_seasonal
sort(ranger_obj_seasonal$variable.importance, decreasing = TRUE)

# logistic regression
# fitting and using final model
final_model_lr_H1N1 <- fit(lr_workflow_H1N1, train_full)
final_model_lr_H1N1

lr_pred_H1N1 <- predict(final_model_lr_H1N1, new_data = data.frame(test_exp, seasonal_vaccine = as.factor(rep(0, nrow(test_exp)))), type = "prob")

final_model_lr_seasonal <- fit(lr_workflow_seasonal, train_full)
final_model_lr_seasonal

lr_pred_seasonal <- predict(final_model_lr_seasonal, new_data = data.frame(test_exp, h1n1_vaccine = as.factor(rep(0, nrow(test_exp)))), type = "prob")
```

```{r tidymodels submission files}
# random forest
# (00)
rf_pred_00 <- bind_cols(respondent_id = test_exp_tr$respondent_id, h1n1_vaccine = rf_pred_H1N1_00$.pred_1, seasonal_vaccine = rf_pred_seasonal_00$.pred_1)

# 0.8528 --> best so far!
# now top 14% ;)
write_csv(rf_pred_00, "rf_00_tidymodels_pred.csv")

# (0)
rf_pred <- bind_cols(respondent_id = test_exp$respondent_id, h1n1_vaccine = rf_pred_H1N1$.pred_1, seasonal_vaccine = rf_pred_seasonal$.pred_1)

# 0.8363 --> worse than second original rf model
write_csv(rf_pred, "rf_tidymodels_pred.csv")

# (1) step_nzv
rf_nzv_pred <- bind_cols(respondent_id = test_exp$respondent_id, h1n1_vaccine = rf_pred_H1N1_nzv$.pred_1, seasonal_vaccine = rf_pred_seasonal_nzv$.pred_1)

# 0.8350 --> worse than (0) random forest
write_csv(rf_nzv_pred, "rf_nzv_tidymodels_pred.csv")

# (2) step_oth
rf_oth_pred <- bind_cols(respondent_id = test_exp$respondent_id, h1n1_vaccine = rf_pred_H1N1_oth$.pred_1, seasonal_vaccine = rf_pred_seasonal_oth$.pred_1)

# 0.8342 --> worse than (0) random forest
write_csv(rf_oth_pred, "rf_oth_tidymodels_pred.csv")

# (3) all integers
rf_int_pred <- bind_cols(respondent_id = test_exp$respondent_id, h1n1_vaccine = rf_pred_H1N1_int$.pred_1, seasonal_vaccine = rf_pred_seasonal_int$.pred_1)

# 0.8355 --> worse than (0) random forest
write_csv(rf_int_pred, "rf_int_tidymodels_pred.csv")

# logistic regression
lr_pred <- bind_cols(respondent_id = test_exp$respondent_id, h1n1_vaccine = lr_pred_H1N1$.pred_1, seasonal_vaccine = lr_pred_seasonal$.pred_1)

# 0.8312 --> worse than (0) random forest
write_csv(lr_pred, "lr_tidymodels_pred.csv")
```

