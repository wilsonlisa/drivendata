---
title: "Flu Shot Learning"
author: "Lisa Wilson"
date: "8/27/2022"
output: pdf_document
---

Example data cleaning, exploration, and model fitting R code for the DrivenData Flu Shot Learning challenge, where the goal is to predict the probabilities that individuals received H1N1 and seasonal flu vaccines. For full (messy) work so far, please see flu_model_build_work_in_progress.rmd.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

setwd("~/Documents/DrivenData/Flu Shot Learning/")

library(tidymodels)
library(tidyverse)
library(workflows)
library(tune)
library(ranger)
library(naniar)
library(nnet)
library(factoextra)
library(xgboost)
library(vip)
```

### Data exploration and manipulation
```{r data}
train_exp <- read.csv("flu_train_features.csv")
train_resp <- read.csv("flu_train_labels.csv")
test_exp <- read.csv("flu_test_features.csv")

summary(train_exp)

# could also do recipe step step_string2factor(all_nominal())
train_exp <- train_exp %>% mutate_if(is.character, as.factor)
test_exp <- test_exp %>% mutate_if(is.character, as.factor)
summary(train_exp)
str(train_exp)

train_full <- inner_join(train_resp, train_exp, by = "respondent_id")
train_full <- train_full %>% 
    mutate(h1n1_vaccine = as.factor(h1n1_vaccine), seasonal_vaccine = as.factor(seasonal_vaccine))
head(train_full)

summary(train_full$h1n1_vaccine)
summary(train_full$seasonal_vaccine)

# correlation of 0.377 between the two vaccine statuses
# higher than/about equal to correlation b/w vaccine status and whether doctor recommended (below), which has been identified as important varb in random forest and boosted tree models
cor(as.numeric(train_full$h1n1_vaccine), as.numeric(train_full$seasonal_vaccine))

# 0.3938905
cor(as.numeric(train_full$h1n1_vaccine), train_full$doctor_recc_h1n1, use = "complete.obs")
# 0.3691901
cor(as.numeric(train_full$seasonal_vaccine), train_full$doctor_recc_seasonal, use = "complete.obs")
```

```{r data exploration}
# health insurance and H1N1 vaccine
summary(train_full$health_insurance)
head(train_full$health_insurance)
ggplot(data = train_full, aes(x = as.factor(health_insurance))) +
    geom_bar(aes(fill = as.factor(h1n1_vaccine))) +
    scale_fill_brewer(palette = "Set2") + 
    labs(x = "Has health insurance", y = "", fill = "Received H1N1 vaccine")
chisq.test(as.factor(train_full$health_insurance), as.factor(train_full$h1n1_vaccine))

# employment_occupation, employment_industry and H1N1 vaccine
ggplot(data = train_full, aes(x = as.factor(h1n1_vaccine))) +
    geom_bar(aes(fill = as.factor(employment_occupation))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Received H1N1 vaccine", y = "", fill = "Employment occupation")
chisq.test(train_full$employment_occupation, train_full$h1n1_vaccine)

ggplot(data = train_full, aes(x = as.factor(h1n1_vaccine))) +
    geom_bar(aes(fill = as.factor(employment_industry))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Received H1N1 vaccine", y = "", fill = "Employment industry")
chisq.test(train_full$employment_industry, train_full$h1n1_vaccine)
```

```{r class imbalance}
# class imbalance in H1N1 vaccine status --> most are 0s, few are 1s
# options: oversampling minority, undersampling majority, class weights
prop.table(table(train_full$h1n1_vaccine))

# more balanced in seasonal vaccine status --> 53% 0s
prop.table(table(train_full$seasonal_vaccine))
```

```{r missing data}
# change blanks to NA
train_full <- mutate_all(train_full, list(~na_if(.,""))) %>%
  mutate_if(is.factor, fct_drop)
test_exp <- mutate_all(test_exp, list(~na_if(.,""))) %>%
  mutate_if(is.factor, fct_drop)

# look into fct_lump (Collapsing the least/most frequent values of a factor into “other”) --> or step_other in recipe
# employment_industry, employment_occupation
sort(summary(train_full$hhs_geo_region)/nrow(train_full))
sort(summary(train_full$employment_industry)/nrow(train_full))
sort(summary(train_full$employment_occupation)/nrow(train_full))

# predictors w/ most missing values
# employment_occupation, employment_industry, health_insurance all around 50%
# income_poverty around 16%
p_missing <- unlist(lapply(train_full, function(x) sum(is.na(x))))/nrow(train_full)
sort(p_missing[p_missing > 0], decreasing = TRUE)

# many observations are missing all three
train_full %>%
  select(employment_occupation, employment_industry, health_insurance) %>%
  gg_miss_upset()

# highest proportion of no health insurance is among NAs
ggplot(train_full, aes(x = employment_occupation)) + 
  geom_bar(aes(fill = as.factor(health_insurance))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment occupation", y = "", fill = "Has health insurance")

# variation in having insurance among occupation
ggplot(drop_na(train_full, employment_occupation), aes(x = employment_occupation)) + 
  geom_bar(aes(fill = as.factor(health_insurance))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment occupation", y = "", fill = "Has health insurance")

# highest proportion of no health insurance is among NAs
ggplot(train_full, aes(x = employment_industry)) + 
  geom_bar(aes(fill = as.factor(health_insurance))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment industry", y = "", fill = "Has health insurance")

# variation in having insurance among industry
ggplot(drop_na(train_full, employment_industry), aes(x = employment_industry)) + 
  geom_bar(aes(fill = as.factor(health_insurance))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment industry", y = "", fill = "Has health insurance")

# most are NA in both industry and occupation
ggplot(train_full, aes(x = employment_industry)) + 
  geom_bar(aes(fill = as.factor(employment_occupation))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment industry", y = "", fill = "Employment occupation")

# more variation of occupation within industry than I expected, but some noticeable patterns
ggplot(drop_na(train_full, employment_industry), aes(x = employment_industry)) + 
  geom_bar(aes(fill = as.factor(employment_occupation))) +
    # scale_fill_brewer(palette = "Set2") + 
    labs(x = "Employment industry", y = "", fill = "Employment occupation")

# need to think through the best way to use / impute for / drop employment_industry, employment_occupation, health_insurance
# can I model each?
# how to determine which predictors are most correlated w/ these three?

# what variables are associated w/ health insurance status?
# basic logistic regression
health_ins_lg <- glm(as.factor(health_insurance) ~ . , family = "binomial", data = subset(train_full, select = -c(h1n1_vaccine, seasonal_vaccine, respondent_id, employment_industry, employment_occupation)))
summary(health_ins_lg)

# predicted probability of individual having health insurance based on above model
# interesting
health_ins_pred <- predict(health_ins_lg, filter(train_full, is.na(health_insurance)), type = "response")
```

```{r data manipulation}
# transform categorical to numerical for certain algorithms
train_full_num <- train_full %>% mutate_if(is.factor, as.numeric) # could also do as.integer
```

```{r transforming variables with high missingness}
# many observations are missing all three
train_full %>%
  select(employment_occupation, employment_industry, health_insurance) %>%
  gg_miss_upset()

# similar between train and test data
test_exp %>%
  select(employment_occupation, employment_industry, health_insurance) %>%
  gg_miss_upset()

# Little's (1988) test statistic to assess if data is missing completely at random (MCAR)
# very low p-value --> not missing completely at random
# look into this further
mcar_test(train_full)

# create new factor levels based on groupings w/ highest NAs from plot above
# (1) employment_occupation and employment_industry both NA
# (2) employment_occupation, employment_industry, and health_insurance all NA
# (3) health_insurance NA but not employment_occupation or employment_industry
train_full_tr <- train_full %>%
  mutate(employment_occupation = fct_expand(employment_occupation, "na_all", "na_emp"), employment_industry = fct_expand(employment_industry, "na_all", "na_emp"), health_insurance = fct_expand(as.factor(health_insurance), "na_all", "na_ins"))

summary(train_full_tr)

train_full_tr <- train_full_tr %>%
  mutate(across(c(employment_occupation, employment_industry, health_insurance), function(x) replace(x, is.na(employment_occupation) & is.na(employment_industry) & is.na(health_insurance), "na_all")),
         across(c(employment_occupation, employment_industry), function(x) replace(x, is.na(employment_occupation) & is.na(employment_industry), "na_emp")),
         health_insurance = replace(health_insurance, is.na(health_insurance) & !is.na(employment_occupation) & !is.na(employment_industry), "na_ins"))

# remaining NA totals in three varbs matches what was expected from plot above
summary(train_full_tr)

miss_var_summary(train_full)
miss_var_summary(train_full_tr) # <1% NAs across all three now

# apply to test_exp
test_exp_tr <- test_exp %>%
  mutate(employment_occupation = fct_expand(employment_occupation, "na_all", "na_emp"), employment_industry = fct_expand(employment_industry, "na_all", "na_emp"), health_insurance = fct_expand(as.factor(health_insurance), "na_all", "na_ins"))

test_exp_tr <- test_exp_tr %>%
  mutate(across(c(employment_occupation, employment_industry, health_insurance), function(x) replace(x, is.na(employment_occupation) & is.na(employment_industry) & is.na(health_insurance), "na_all")),
         across(c(employment_occupation, employment_industry), function(x) replace(x, is.na(employment_occupation) & is.na(employment_industry), "na_emp")),
         health_insurance = replace(health_insurance, is.na(health_insurance) & !is.na(employment_occupation) & !is.na(employment_industry), "na_ins"))

# look into other features of naniar
```

### Random forest model
#### Using `tidymodels` walkthrough
```{r random forest}
# https://www.rebeccabarter.com/blog/2020-03-25_machine_learning/
# class imbalance walkthrough: https://juliasilge.com/blog/himalayan-climbing/

# split full training set into training and testing
# try adding strata argument for h1n1_vaccine split
set.seed(4242)
# (00) using transformed high NA dataset
flu_split <- initial_split(train_full_tr, prop = 0.8)

# extract training and testing sets
flu_train <- training(flu_split)
flu_test <- testing(flu_split)

# create CV object from training data
# might consider setting strata = h1n1_vaccine to address class imbalance
flu_cv <- vfold_cv(flu_train, v = 5)

# define the recipe
H1N1_recipe_00 <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(h1n1_vaccine ~ ., 
         data = train_full_tr) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "seasonal_vaccine")) %>%
  step_impute_knn(all_predictors())

seasonal_recipe_00 <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(seasonal_vaccine ~ ., 
         data = train_full_tr) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "h1n1_vaccine")) %>%
  step_impute_knn(all_predictors())

# specify the model
# random forest
rf_model_H1N1 <- 
  # specify that the model is a random forest
  rand_forest() %>%
  # specify that the `mtry` parameter needs to be tuned
  #set_args(mtry = tune(), trees = tune()) %>%
  set_args(mtry = tune()) %>%
  # select the engine/package that underlies the model
  set_engine("ranger", importance = "permutation") %>%
  # choose either the continuous regression or binary classification mode
  set_mode("classification") 

rf_model_flu <- rf_model_H1N1

# set the workflow
rf_workflow_H1N1_00 <- workflow() %>%
  # add the recipe
  add_recipe(H1N1_recipe_00) %>%
  # add the model
  add_model(rf_model_H1N1)

rf_workflow_seasonal_00 <- workflow() %>%
  # add the recipe
  add_recipe(seasonal_recipe_00) %>%
  # add the model
  add_model(rf_model_flu)

# parameter tuning
param_tune <- c(round(sqrt(ncol(train_full_tr[,-c(1:3)])))-1, 
                round(sqrt(ncol(train_full_tr[,-c(1:3)]))),
                round(sqrt(ncol(train_full_tr[,-c(1:3)])))+1)

# specify which values want to try
rf_grid <- expand.grid(mtry = param_tune)

# extract results
rf_tune_results_H1N1_00 <- rf_workflow_H1N1_00 %>%
  tune_grid(resamples = flu_cv, # CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(accuracy, roc_auc) # metrics
            #metrics = metric_set(roc_auc)
            )

rf_tune_results_seasonal_00 <- rf_workflow_seasonal_00 %>%
  tune_grid(resamples = flu_cv, # CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(accuracy, roc_auc) # metrics
            )

# finalize workflow
param_final_H1N1_00 <- rf_tune_results_H1N1_00 %>%
  select_best(metric = "roc_auc") # mtry = 5

rf_workflow_H1N1_00 <- rf_workflow_H1N1_00 %>%
  finalize_workflow(param_final_H1N1_00)

param_final_seasonal_00 <- rf_tune_results_seasonal_00 %>%
  select_best(metric = "roc_auc") # mtry = 5

rf_workflow_seasonal_00 <- rf_workflow_seasonal_00 %>%
  finalize_workflow(param_final_seasonal_00)

# evaluate model on "test" set
rf_fit_H1N1_00 <- rf_workflow_H1N1_00 %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

test_performance_rf_H1N1_00 <- rf_fit_H1N1_00 %>% collect_metrics()

rf_fit_seasonal_00 <- rf_workflow_seasonal_00 %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

test_performance_rf_seasonal_00 <- rf_fit_seasonal_00 %>% collect_metrics()

test_predictions_rf_H1N1_00 <- rf_fit_H1N1_00 %>% collect_predictions()

test_predictions_rf_seasonal_00 <- rf_fit_seasonal_00 %>% collect_predictions()

# generate a confusion matrix
# most of true 1s predicted as 0s for H1N1
rf_cm_H1N1 <- test_predictions_rf_H1N1_00 %>% 
  conf_mat(truth = h1n1_vaccine, estimate = .pred_class)
rf_cm_H1N1
autoplot(rf_cm_H1N1, type = "mosaic")

test_predictions_rf_H1N1_00 %>%
  ggplot() +
  geom_density(aes(x = .pred_1, fill = h1n1_vaccine), 
               alpha = 0.5)

# not bad for seasonal
test_predictions_rf_seasonal_00 %>% 
  conf_mat(truth = seasonal_vaccine, estimate = .pred_class)

# fitting final model and predicting for test set
final_model_rf_H1N1_00 <- fit(rf_workflow_H1N1_00, train_full_tr)

rf_pred_H1N1_00 <- predict(final_model_rf_H1N1_00, new_data = data.frame(test_exp_tr, seasonal_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

final_model_rf_seasonal_00 <- fit(rf_workflow_seasonal_00, train_full_tr)

rf_pred_seasonal_00 <- predict(final_model_rf_seasonal_00, new_data = data.frame(test_exp_tr, h1n1_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

# submission file
rf_pred_00 <- bind_cols(respondent_id = test_exp_tr$respondent_id, h1n1_vaccine = rf_pred_H1N1_00$.pred_1, seasonal_vaccine = rf_pred_seasonal_00$.pred_1)

write_csv(rf_pred_00, "rf_00_tidymodels_pred.csv") # AUROC = 0.8528
```

### Logistic regression
#### Using `tidymodels` workflow
```{r logistic regression}
# split full training set into training and testing
# try adding strata argument for h1n1_vaccine split
set.seed(4242)
flu_split <- initial_split(train_full_tr, prop = 0.8)

# extract training and testing sets
flu_train <- training(flu_split)
flu_test <- testing(flu_split)

# create CV object from training data
# might consider setting strata = h1n1_vaccine to address class imbalance
flu_cv <- vfold_cv(flu_train, v = 5)

# define the recipe
H1N1_recipe <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(h1n1_vaccine ~ ., 
         data = train_full_tr) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "seasonal_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_normalize(all_numeric())

seasonal_recipe <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(seasonal_vaccine ~ ., 
         data = train_full_tr) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "h1n1_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_normalize(all_numeric())

# specify the model
# logistic regression
lr_model_H1N1 <- 
  # specify that the model is a logistic regression
  logistic_reg() %>%
  # select the engine/package that underlies the model
  set_engine("glm") %>%
  # choose either the continuous regression or binary classification mode
  set_mode("classification") 

lr_model_flu <- lr_model_H1N1

# set the workflow
lr_workflow_H1N1 <- workflow() %>%
  # add the recipe
  add_recipe(H1N1_recipe) %>%
  # add the model
  add_model(lr_model_flu)

lr_workflow_seasonal <- workflow() %>%
  # add the recipe
  add_recipe(seasonal_recipe) %>%
  # add the model
  add_model(lr_model_flu)

# can do parameter tuning? regularization like in benchmark?
# think I'd need to use glmnet
# https://compgenomr.github.io/book/logistic-regression-and-regularization.html

# evaluate model on "test" set
lr_fit_H1N1 <- lr_workflow_H1N1 %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split, metrics = metric_set(accuracy, roc_auc))

test_performance_lr_H1N1 <- lr_fit_H1N1 %>% collect_metrics()
test_performance_lr_H1N1

lr_fit_seasonal <- lr_workflow_seasonal %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split, metrics = metric_set(accuracy, roc_auc))

test_performance_lr_seasonal <- lr_fit_seasonal %>% collect_metrics()
test_performance_lr_seasonal

# generate predictions from the test set
test_predictions_lr_H1N1 <- lr_fit_H1N1 %>% collect_predictions()
test_predictions_lr_H1N1

test_predictions_lr_seasonal <- lr_fit_seasonal %>% collect_predictions()
test_predictions_lr_seasonal

# generate a confusion matrix
# like random forest, most of true 1s predicted as 0s
test_predictions_lr_H1N1 %>% 
  conf_mat(truth = h1n1_vaccine, estimate = .pred_class)

test_predictions_lr_seasonal %>% 
  conf_mat(truth = seasonal_vaccine, estimate = .pred_class)

# fitting final model and predicting for test set
final_model_lr_H1N1 <- fit(lr_workflow_H1N1, train_full_tr)

lr_pred_H1N1 <- predict(final_model_lr_H1N1, new_data = data.frame(test_exp_tr, seasonal_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

final_model_lr_seasonal <- fit(lr_workflow_seasonal, train_full_tr)

lr_pred_seasonal <- predict(final_model_lr_seasonal, new_data = data.frame(test_exp_tr, h1n1_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

# submission file
lr_pred <- bind_cols(respondent_id = test_exp_tr$respondent_id, h1n1_vaccine = lr_pred_H1N1$.pred_1, seasonal_vaccine = lr_pred_seasonal$.pred_1)

write_csv(lr_pred, "lr2_tidymodels_pred.csv") # AUROC = 0.8474 --> worse than random forest
```

### xgboost model
#### Using `tidymodels` workflow
```{r boosted trees}
# to try:
# try step_smote() on h1n1_vaccine to address class imbalance -- apply SMOTE algorithm to "generate new examples of the minority class using nearest neighbors of these cases" https://themis.tidymodels.org/reference/step_smote.html
# try other classification methods: boost_tree (xgboost), some discriminant model (discrim_regularized?), single layer neural network / mlp, multinom_reg (nnet, glmnet), nearest_neighbor (kknn)

# split full training set into training and testing
# try adding strata argument for h1n1_vaccine split
set.seed(4242)
flu_split <- initial_split(train_full_tr, prop = 0.8)

# extract training and testing sets
flu_train <- training(flu_split)
flu_test <- testing(flu_split)

# create CV object from training data
# might consider setting strata = h1n1_vaccine to address class imbalance
flu_cv <- vfold_cv(flu_train, v = 5)

# define the recipe
H1N1_recipe_001 <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(h1n1_vaccine ~ ., 
         data = train_full_tr) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "seasonal_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_dummy(all_nominal_predictors())

seasonal_recipe_001 <- 
  # which consists of the formula (outcome ~ predictors)
  recipe(seasonal_vaccine ~ ., 
         data = train_full_tr) %>%
  # and some pre-processing steps
  step_rm(c("respondent_id", "h1n1_vaccine")) %>%
  step_impute_knn(all_predictors()) %>%
  step_dummy(all_nominal_predictors())

# looking to https://juliasilge.com/blog/xgboost-tune-volleyball/
# https://www.r-bloggers.com/2020/05/using-xgboost-with-tidymodels/
# define the xgboost model
# could add to set_engine: objective = "binary:logistic"
# if change set_mode to "regression" (I think)
xgboost_model <- 
  boost_tree() %>%
  set_args(trees = 1000,
  tree_depth = tune(), min_n = tune(), 
  loss_reduction = tune(), # first three: model complexity
  sample_size = tune(), mtry = tune(), # randomness
  learn_rate = tune()) %>% # step size
  set_engine("xgboost", event_level = "second") %>% 
  set_mode("classification")

# set the workflow
xgb_workflow_H1N1_001 <- workflow() %>%
  add_recipe(H1N1_recipe_001) %>%
  add_model(xgboost_model)

xgb_workflow_seasonal_001 <- workflow() %>%
  add_recipe(seasonal_recipe_001) %>%
  add_model(xgboost_model)

xgboost_grid <- 
  grid_max_entropy(
    tree_depth(),
    min_n(),
    loss_reduction(),
    sample_size = sample_prop(),
    finalize(mtry(), flu_train),
    learn_rate(),
    size = 10
  )

set.seed(6767)
# only takes ~40 minutes!
xgb_tune_results_H1N1_001 <- xgb_workflow_H1N1_001 %>%
  tune_grid(resamples = flu_cv, #CV object
            grid = xgboost_grid, # grid of values to try
            control = control_grid(parallel_over = "resamples")
            )

set.seed(5656)
# only takes ~40 minutes!
xgb_tune_results_seasonal_001 <- xbg_workflow_seasonal_001 %>%
  tune_grid(resamples = flu_cv, #CV object
            grid = xgboost_grid, # grid of values to try
            control = control_grid(parallel_over = "resamples")
            )

# can also read in saved parameters (same for H1N1_001, seasonal_001, H1N1_002)
#xgb_params_001 <- as_tibble(read_csv("param_xgb_H1N1_002.csv"))

# finalize workflow
param_xgb_H1N1_001 <- xgb_tune_results_H1N1_001 %>%
  select_best(metric = "roc_auc")

xgb_workflow_H1N1_001 <- xgb_workflow_H1N1_001 %>%
  finalize_workflow(param_xgb_H1N1_001)

# if using saved param values
#xgb_workflow_H1N1_001 <- xgb_workflow_H1N1_001 %>%
  #finalize_workflow(xgb_params_001)

# same as H1N1
param_xgb_seasonal_001 <- xgb_tune_results_seasonal_001 %>%
  select_best(metric = "roc_auc")

xgb_workflow_seasonal_001 <- xgb_workflow_seasonal_001 %>%
  finalize_workflow(param_xgb_seasonal_001)

# if using saved param values
#xgb_workflow_seasonal_001 <- xgb_workflow_seasonal_001 %>%
  #finalize_workflow(xgb_params_001)

# variable importance graph
# top 3: doctor_recc_h1n1 (>0.20), opinion_h1n1_risk, opinion_h1n1_vacc_effective (between 0.10-0.15)
# top 10: doctor_recc_h1n1, opinion_h1n1_risk, opinion_h1n1_vacc_effective, health_insurance_X1, opinion_seas_risk, opinion_seas_vacc_effective, health_insurance_na_ins, doctor_recc_seasonal, health_worker, health_insurance_na_all
xgb_workflow_H1N1_001 %>%
  fit(data = flu_train) %>%
  extract_fit_parsnip() %>%
  vip(geom = "point")

vip_xgb_H1N1_tib <- xgb_workflow_H1N1_001 %>%
  fit(data = flu_train) %>%
  extract_fit_parsnip() %>%
  vi()

vip_xgb_seasonal_tib <- xgb_workflow_seasonal_001 %>%
  fit(data = flu_train) %>%
  extract_fit_parsnip() %>%
  vi()

# evaluate model on "test" set
xgb_fit_H1N1_001 <- xgb_workflow_H1N1_001 %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

# seem high/good
test_performance_xgb_H1N1_001 <- xgb_fit_H1N1_001 %>% collect_metrics()

xgb_fit_seasonal_001 <- xgb_workflow_seasonal_001 %>%
  # fit on the training set and evaluate on test set
  last_fit(flu_split)

# seem high/good
test_performance_xgb_seasonal_001 <- xgb_fit_seasonal_001 %>% collect_metrics()

# generate predictions from the test set
test_predictions_xgb_H1N1_001 <- xgb_fit_H1N1_001 %>% collect_predictions()

test_predictions_xgb_seasonal_001 <- xgb_fit_seasonal_001 %>% collect_predictions()

# fitting final model and predicting for test set
## look into: "WARNING: amalgamation/../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
final_model_xgb_H1N1_001 <- fit(xgb_workflow_H1N1_001, train_full_tr)

xgb_pred_H1N1_001 <- predict(final_model_xgb_H1N1_001, new_data = data.frame(test_exp_tr, seasonal_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

## look into same warning
final_model_xgb_seasonal_001 <- fit(xgb_workflow_seasonal_001, train_full_tr)

xgb_pred_seasonal_001 <- predict(final_model_xgb_seasonal_001, new_data = data.frame(test_exp_tr, h1n1_vaccine = as.factor(rep(0, nrow(test_exp_tr)))), type = "prob")

# submission file
xgb_pred_001 <- bind_cols(respondent_id = test_exp_tr$respondent_id, h1n1_vaccine = xgb_pred_H1N1_001$.pred_1, seasonal_vaccine = xgb_pred_seasonal_001$.pred_1)

write_csv(xgb_pred_001, "xgb_001_tidymodels_pred.csv") # AUROC = 0.8572 --> best so far (top 12% on leaderboard)
```

