---
title: "Richter's Predictor"
author: "Lisa Wilson"
date: "8/24/2021"
output: pdf_document
---

```{r setup, include=FALSE}
setwd("~/Documents/DrivenData/Richter's Predictor/")

library(tidyverse)
library(magrittr)
library(MASS)
library(class)
library(neuralnet)
library(randomForest)
library(caret)
library(caretEnsemble)
library(doParallel)
library(rpart)
library(doMC)

remotes::install_github("LqNoob/Machine-Learning-Evaluation-Metrics")
library(MLmetrics)

knitr::opts_chunk$set(echo = TRUE)
```
### Data exploration
```{r data}
train_exp <- read.csv("richter_train_features.csv")
train_resp <- read.csv("richter_train_labels.csv")
test_exp <- read.csv("richter_test_features.csv")

# geo_level_1_id, geo_level_2_id, geo_level_3_id: geographic region in which building exists, from largest (level 1) to most specific sub-region (level 3)
# do some clustering, multivariate, PCR on these?

# recode categoricals
cats <- names(train_exp)[c(9:27,29:39)]

train_exp <- train_exp %<>% mutate_at(cats, factor)
test_exp <- test_exp %<>% mutate_at(cats, factor)

train_resp$damage_grade <- factor(train_resp$damage_grade)

train_full <- inner_join(train_resp, train_exp, by = "building_id")
```

```{r class imbalance}
# class imbalance --> most are 2s, few are 1s
prop.table(table(train_full$damage_grade))
```

### Model selection
```{r stepAIC}
set.seed(42)

# some smaller samples --> ~1% of full dataset
train_samp1 <- sample_n(train_full, 2600)
train_samp2 <- sample_n(train_full, 2600)
train_samp3 <- sample_n(train_full, 2600)

# only one record overlaps
nrow(inner_join(inner_join(train_samp1, train_samp2, by = "building_id"), train_samp3, by = "building_id"))

stepAIC(polr(damage_grade ~ .-building_id, data = train_samp1))
# AIC = 4244.951
# damage_grade ~ count_floors_pre_eq + area_percentage + 
    # foundation_type + roof_type + other_floor_type + position + 
    # has_superstructure_adobe_mud + has_superstructure_mud_mortar_stone + 
    # has_superstructure_stone_flag + has_superstructure_cement_mortar_brick +
    # has_superstructure_timber + has_superstructure_bamboo + has_superstructure_rc_engineered + 
    # legal_ownership_status + count_families + has_secondary_use

stepAIC(polr(damage_grade ~ .-building_id, data = train_samp2))
# AIC = 4231.477 
# damage_grade ~ geo_level_2_id + count_floors_pre_eq + 
    # area_percentage + foundation_type + roof_type + ground_floor_type + 
    # other_floor_type + has_superstructure_adobe_mud + has_superstructure_mud_mortar_stone + 
    # has_superstructure_stone_flag + has_superstructure_timber + 
    # legal_ownership_status + has_secondary_use + has_secondary_use_agriculture + has_secondary_use_other

stepAIC(polr(damage_grade ~ .-building_id, data = train_samp3))
# AIC = 4176.558 
# damage_grade ~ count_floors_pre_eq + height_percentage + 
    # foundation_type + roof_type + ground_floor_type + other_floor_type + 
    # position + has_superstructure_adobe_mud + has_superstructure_mud_mortar_stone + 
    # has_superstructure_stone_flag + has_superstructure_cement_mortar_stone +
    # has_superstructure_cement_mortar_brick + has_superstructure_timber + 
    # has_superstructure_rc_engineered + has_superstructure_other + 
    # count_families + has_secondary_use + has_secondary_use_agriculture + 
    # has_secondary_use_hotel + has_secondary_use_rental + has_secondary_use_institution
```

```{r initial model}
# choose initial model based on varbs that show up in at least two of the best models
model1 <- polr(damage_grade ~ count_floors_pre_eq + area_percentage + foundation_type + roof_type + ground_floor_type + other_floor_type + position + has_superstructure_adobe_mud + has_superstructure_mud_mortar_stone + has_superstructure_stone_flag + has_superstructure_cement_mortar_brick + has_superstructure_timber + has_superstructure_rc_engineered + legal_ownership_status + count_families + has_secondary_use + has_secondary_use_agriculture, data = train_full)

summary(model1)
# AIC = 422351.95

# should also try different link functions
```

```{r model1 F1 train}
model1_train_predict <- data.frame(predict(model1, newdata = train_exp, type = "p"))
colnames(model1_train_predict) <- c("1", "2", "3")

# from stackoverflow user tmfmnk https://stackoverflow.com/a/63457743
model1_train_predict_df <- model1_train_predict %>%
 rowwise() %>%
 mutate(damage_grade_pred = names(.)[which.max(c_across(everything()))])

F1_Score_micro(model1_train_predict_df$damage_grade_pred, train_full$damage_grade, c("1", "2", "3"))
# 0.5767514
```


```{r model1 predict}
model1_predict <- data.frame(predict(model1, newdata = test_exp, type = "p"))
colnames(model1_predict) <- c("1", "2", "3")

model1_predict_df <- model1_predict %>%
 rowwise() %>%
 mutate(damage_grade = names(.)[which.max(c_across(everything()))])

model1_submission <- data.frame(building_id = test_exp$building_id, damage_grade = as.integer(model1_predict_df$damage_grade))
write.csv(model1_submission, "model1_predict.csv", row.names = FALSE)
# F1 = 0.5725 (worse than benchmark)

# easier way to predict
model1_predict_easier <- data.frame(building_id = test_exp$building_id, 
                                    damage_grade = as.integer(predict(model1, newdata = test_exp, type = "class")))
```

```{r polr2}
# everything but building_id and specific secondary_use varbs
model3_tr <- polr(damage_grade ~ ., data = train_primary[,2:30])
model3_tr_pred <- predict(model3_tr, train_hold, type = "class")

F1_Score_micro(train_hold$damage_grade, model3_tr_pred, labels = c("1", "2", "3"))
# 0.5794038 --> bad
```

### PCA
```{r PCA}
# explore later
```

### Machine learning
#### Random forest
```{r randfor}
set.seed(42)

rf1 <- randomForest(train_primary[,-c(1:2)], train_primary$damage_grade)
train_pred <- predict(rf1, train_hold[,-c(1:2)], type = "class")
head(train_pred)

rf_pred_tab <- table(train_pred, train_hold$damage_grade)
# error rates for each grade
1 - rf_pred_tab[1,1]/sum(rf_pred_tab[1,]) # 0.3122934
1 - rf_pred_tab[2,2]/sum(rf_pred_tab[2,]) # 0.2797555
1 - rf_pred_tab[3,3]/sum(rf_pred_tab[3,]) # 0.2462976

F1_Score_micro(train_hold$damage_grade, train_pred, c("1", "2", "3"))
# F1 = 0.7266346 --> better!

rf1_full <- randomForest(train_full[,-c(1:2)], train_full$damage_grade)
rf1_test_pred <- predict(rf1_full, test_exp[,-1], type = "class")
rf1_test_submission <- data.frame(building_id = test_exp$building_id, 
                                  damage_grade = rf1_test_pred)
write.csv(rf1_test_submission, "rf1_predict.csv", row.names = FALSE)
# F1 = 0.7301
# 619/4572 --> top ~13.5%
# best model so far

# what are the important varbs?
arrange(data.frame(rf1_full$importance), desc(MeanDecreaseGini))
rf1_imp_varbs <- row.names(filter(data.frame(rf1_full$importance), MeanDecreaseGini > 1000))

varImpPlot(rf1_full)
rf1_vimp_varbs <- row.names(filter(data.frame(rf1_full$importance), MeanDecreaseGini > 1800))
```

```{r rf rerun}
set.seed(42)
registerDoMC(2)

# rerun tree with very important varbs
node_size <- nrow(train_primary)*.001

rf2 <- randomForest(train_primary[,rf1_vimp_varbs], train_primary$damage_grade, nodesize = node_size)
rf2_pred <- predict(rf2, train_hold, type = "class")

F1_Score_micro(train_hold$damage_grade, rf2_pred, labels = c("1", "2", "3"))
# 0.6950385 --> worse than full model

# rerun full tree with more nodes
rf3 <- randomForest(train_primary[,-c(1:2)], train_primary$damage_grade, nodesize = node_size)
rf3_pred <- predict(rf3, train_hold, type = "class")

F1_Score_micro(train_hold$damage_grade, rf3_pred, labels = c("1", "2", "3"))
# 0.6980577
# increasing nodesize is just to increase speed

# rf3_full <- randomForest(train_full[,-c(1:2)], train_full$damage_grade, nodesize = node_size)
```

```{r rf+polr}
model2_tr <- polr(damage_grade ~ ., data = train_primary[,c("damage_grade", rf1_imp_varbs)])
model2_tr_pred <- predict(model2_tr, train_hold, type = "class")

F1_Score_micro(train_hold$damage_grade, model2_tr_pred, labels = c("1", "2", "3"))
# 0.5798654 --> so also bad

model2 <- polr(damage_grade ~ ., data = train_full[,c("damage_grade", rf1_imp_varbs)])
```

#### Recursive partitioning (CART-like)
```{r rpart}
model4_tr <- rpart(damage_grade ~ .-building_id, data = train_primary, method = "class")
model4_tr_pred <- predict(model4_tr, train_hold, type = "class")

F1_Score_micro(train_hold$damage_grade, model4_tr_pred, labels = c("1", "2", "3"))
# 0.6407308

summary(model4_tr)
plot(model4_tr); text(model4_tr, use.n = TRUE, cex = 0.8)
```

